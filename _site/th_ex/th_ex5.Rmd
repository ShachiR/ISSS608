---
title: "Take Home Exercise-5"
description: |
  Reveal the social areas of the city of Engagement, Ohio USA.
author:
  - name: Shachi Anirudha Raodeo 
  - url: https://github.com/ShachiR/ISSS608
    affiliation: School of Computing and Information Systems
date: "`r Sys.Date()`"
output: distill::distill_article
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      eval = TRUE,
                      message = FALSE)
```

## The Task
This take-home exercise aims to reveal reveal social areas and visualizing and analyzing locations with traffic bottleneck of the city of Engagement, Ohio USA by using visualization techniques in R.

Assuming the volunteers are representative of the city’s population, characterize the distinct areas of the city that you identify. For each area you identify, provide your rationale and supporting data. 

Where are the busiest areas in Engagement? Are there traffic bottlenecks that should be addressed? Explain your rationale.

Links to the dataset:

[`TravelJournal.csv`](https://vast-challenge.github.io/2022/)
[`Employers.csv`](https://vast-challenge.github.io/2022/)
[`Pubs.csv`](https://vast-challenge.github.io/2022/)
[`Restaurants.csv`](https://vast-challenge.github.io/2022/)
[`Buildings.csv`](https://vast-challenge.github.io/2022/)
[`Schools.csv`](https://vast-challenge.github.io/2022/)
[`Apartments.csv`](https://vast-challenge.github.io/2022/)

## Step-by-step Data Visualisation

### Installing and launching R packages

Packages, namely `tidyverse, sftime, ViSiElse, tmap are required for this exercise. This code chunk installs the required packages and loads them onto RStudio environment.


```{r warning=FALSE}
packages = c('tidyverse','ggplot2','ggdist', 'ggridges','patchwork', 'ggthemes','hrbrthemes','ggrepel','ggforce',"HH","vcd",'scales','grid','gridExtra','formattable','readr', 'ggiraph', 'plotly', 'DT', 'gganimate','readxl','gifski','gapminder','treemap','treemapify','rPackedBar','ggstatsplot','ggside','broom','crosstalk','ViSiElse','zoo', 'lubridate', 'remotes', 'trelliscopejs','data.table','sf','tmap','sf','clock','sftime','rmarkdown')

for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

## Data Preparation

### Data Source
The dataset used in this exercise is Participants.csv, published by the IEEE for [VAST challenge 2022] (https://vast-challenge.github.io/2022/) 

### Importing the dataset

The code chunk below imports *Buildings.csv* , *TravelJournal.csv*,  *ParticipantStatusLogs10.csv*, *Schools.csv*, *Employers.csv*, *Pubs.csv*, *Restaurants.csv* and *Apartments.csv* from the data folder into R by using [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) function of **readr** and saves it as Tibble data frame called *buildings*, *travel*, *logs*, *schools*, *employers*, *pubs*, *Restaurants* and  *apartments* 

The *TravelJournal.csv* contains information about participants’ motivation for movement around the city.


```{r eval=FALSE}
travel <- read_csv("data/TravelJournal.csv")
summary(travel)
```

```{r}
schools <- read_sf("data/Schools.csv", 
                   options = "GEOM_POSSIBLE_NAMES=location")
pubs <- read_sf("data/Pubs.csv", 
                   options = "GEOM_POSSIBLE_NAMES=location")
restaurants <- read_sf("data/Restaurants.csv", 
                   options = "GEOM_POSSIBLE_NAMES=location")
buildings <- read_sf("data/Buildings.csv", 
                   options = "GEOM_POSSIBLE_NAMES=location")
apartments <- read_sf("data/Apartments.csv", 
                   options = "GEOM_POSSIBLE_NAMES=location")
employers <- read_sf("data/Employers.csv", 
                   options = "GEOM_POSSIBLE_NAMES=location")


```

```{r eval=FALSE}
logs <- read_sf("data/ParticipantStatusLogs10.csv", 
                options = "GEOM_POSSIBLE_NAMES=currentLocation")
glimpse(logs)
```

## Data Wrangling 

The Travel Journal contains travel data of a participant towards Work/Home Commute, Eating, Coming Back From Restaurant,Recreation (Social Gathering), Going Back to Home.

The other schools, buildings, restaurants, pubs, apartments and employers gives us location of distinct places in the city.

Participant logs gives us the routine log file of a participant over a certain time period.

### Calculating Amount Spent

Calculating *the total amount spent at the location as a difference of the starting balance and ending balance* in the travel journal gives us the amount spent by the participant at a particular location.

```{r eval=FALSE}
travel$amountSpent <- travel$endingBalance -travel$startingBalance
```


### Extract information from timestamp

We use weekdays(), day(), month(), year() functions to extract the day of the week, date, moth and year of checkin to perform time series visualizations.


### Calculate the time spent at a particular place and the travel time

Calculate travel time as the difference between the travel start time and the travel end time and calculate the time spent as the difference of check in and check out times.


```{r eval=FALSE}

data_travel= travel%>%
  mutate(weekday = weekdays(checkInTime),
         day = day(checkInTime),
         month=as.character(checkInTime,"%b %y"),
         year = year(checkInTime),
         monthYear = floor_date(checkInTime, "month"),
         travelEndLocationId=as.character(travelEndLocationId),
         timeSpent = checkOutTime - checkInTime,
         travelTime = travelEndTime- travelStartTime,
         participantId=as.character(participantId),
         purpose=as.character(purpose))

data_travel$timeSpent <- as.numeric(as.character(data_travel$timeSpent))
data_travel$travelTime <- as.numeric(as.character(data_travel$travelTime))

``` 

### Filter necessary columns

```{r eval=FALSE}
data_travel <- data_travel[,c("participantId","travelStartLocationId", "travelEndLocationId", "purpose", "checkInTime", "amountSpent","timeSpent","travelTime","weekday","day","month","year","monthYear")]
```

### Save files as RDS

```{r eval=FALSE}
saveRDS ( data_travel, 'data/data_travel.rds')
saveRDS ( logs, 'data/logs.rds')
```

```{r}
data_travel <- readRDS ( 'data/data_travel.rds')
head (data_travel)

logs <- readRDS ( 'data/logs.rds')
head(logs)
```

## Data Visualization

### Buildings present in Ohio, USA

```{r}
logs_path <- logs %>%
  mutate(Timestamp = date_time_parse(timestamp,
                                     zone= "",
                                     format = "%Y-%m-%dT%H:%M:%S"))%>%
  mutate(day=get_day(Timestamp))%>%
  filter(currentMode == "Transport")
```

```{r }
tmap_mode("view")
tm_shape(buildings)+
tm_polygons(col = "grey60",
           size = 1,
           border.col = "black",
           border.lwd = 1)
tmap_mode("plot")
```

### Location of Employers present in Ohio USA

We notice that employers are distributed throughout the city with a maximum number in the central part of the city which appears more connected.

```{r}
tmap_mode("view")
tm_shape(buildings)+
tm_polygons(col = "grey60",
           size = 1,
           border.col = "black",
           border.lwd = 1) +
tm_shape(employers) +
  tm_dots(col = "blue")
```

### Location of Schools present in Ohio USA

Since we have only one school present in the city of engagement Ohio, USA. we notice that two schools are present in the north east block of the city, one in th central east and one in the southern block.

```{r}
tmap_mode("view")
tm_shape(buildings)+
tm_polygons(col = "grey60",
           size = 1,
           border.col = "black",
           border.lwd = 1) +
tm_shape(schools) +
  tm_dots(col = "yellow")
```

### Distribution of Restaurants in Ohio, USA

It is found that the restaurants are more distributed towards the northen and central blovks of the city as compared to the southern block.
The southern block only hosts three restaurants.

```{r}
tmap_mode("view")
tm_shape(buildings)+
tm_polygons(col = "grey60",
           size = 1,
           border.col = "black",
           border.lwd = 1) +
tm_shape(restaurants) +
  tm_dots(col = "red")
```

### Distibution of Apartments in Ohio USA

Housing locations/ apartments are located in clusters in certain blocks of the city.

```{r}
tmap_mode("view")
tm_shape(buildings)+
tm_polygons(col = "grey60",
           size = 0.5,
           border.col = "black",
           border.lwd = 1) +
tm_shape(apartments) +
  tm_dots(col = "orange")
```

```{r}
hex_buildings <- st_make_grid(buildings, 
                    cellsize=100, 
                    square=FALSE) %>%
  st_sf() %>%
  rowid_to_column('hex_id_buil')

points_in_hex_buil <- st_join(logs_path, 
                         hex_buildings, 
                         join=st_within) %>%
  st_set_geometry(NULL) %>%
  count(name='pointCount', hex_id_buil)
head(points_in_hex_buil)

```


```{r}
hex_combined_buil <- hex_buildings %>%
  left_join(points_in_hex_buil, 
            by = 'hex_id_buil') %>%
  replace(is.na(.), 0)

tm_shape(hex_combined_buil %>%
           filter(pointCount > 0))+
  tm_fill("pointCount",
          n = 8,
          style = "quantile") +
  tm_borders(alpha = 0.1)
```

```{r}
hex_employers <- st_make_grid(employers, 
                    cellsize=100, 
                    square=FALSE) %>%
  st_sf() %>%
  rowid_to_column('hex_id_emp')

points_in_hex_emp <- st_join(logs_path, 
                         hex_employers, 
                         join=st_within) %>%
  st_set_geometry(NULL) %>%
  count(name='pointCount', hex_id_emp)
head(points_in_hex_emp)
```

```{r}
hex_combined_emp <- hex_employers %>%
  left_join(points_in_hex_emp, 
            by = 'hex_id_emp') %>%
  replace(is.na(.), 0)

tm_shape(hex_combined_emp %>%
           filter(pointCount > 0))+
  tm_fill("pointCount",
          n = 8,
          style = "quantile",colorNA = 'white', palette = "-magma") +
  tm_borders(alpha = 0.1)
```

```{r}

```



